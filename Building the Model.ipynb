{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import seaborn and matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import OneHotEncoder, MinMaxScaler, and FunctionTransformer from sklearn.preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, FunctionTransformer\n",
    "\n",
    "# Import Pipeline and FeatureUnion\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import LogisticRegression from sklearn.linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import LinearSVC from sklearn.svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import RandomForestClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import roc_auc_score from sklearn.metrics\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the final working data (encoded)\n",
    "train_df = pd.read_csv('./Intermediate_Data/encoded_train.csv', encoding='utf-8', index_col=0)\n",
    "\n",
    "# Import the test data\n",
    "test_df = pd.read_csv('./Intermediate_Data/encoded_test.csv', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Approach\n",
    "For the development of this model, I will be using pipelines with an encoding step (OneHotEncoder) and a modeling step (LogisticRegression/LinearSVC/DecisionTreeClassifier/RandomForestClassifier)). I will attempt a combination of different variables (exclude some of the variables that were determined as poor predictors of the target variable). Additionally, I may choose to apply feature importance to the non-binary categorical data to do some feature selection if the model is having difficulty training.\n",
    "\n",
    "Additionally, I may choose to performing some preprocessing steps on the numerical data depending on the performance of the model.\n",
    "\n",
    "### Metrics\n",
    "For the Kaggle competition, the scoring is done via area under the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>ONGOING_CREDIT</th>\n",
       "      <th>TOTAL_CLOSED</th>\n",
       "      <th>CLOSED_CREDIT</th>\n",
       "      <th>MONTHS_BALANCE</th>\n",
       "      <th>SK_DPD</th>\n",
       "      <th>NET_PAID</th>\n",
       "      <th>PREV_CREDIT</th>\n",
       "      <th>DAYS_TERMINATION</th>\n",
       "      <th>NET_PAYMENT</th>\n",
       "      <th>PAYMENT_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>383067.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3402045.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>207400.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10159641.0</td>\n",
       "      <td>-527.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189037.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60318.0</td>\n",
       "      <td>-714.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3745395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9733149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-29857.365</td>\n",
       "      <td>-240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET  NAME_CONTRACT_TYPE  FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "0      100002       1                   0                1             0   \n",
       "1      100003       0                   0                0             0   \n",
       "2      100004       0                   1                1             0   \n",
       "3      100006       0                   0                1             0   \n",
       "4      100007       0                   0                1             0   \n",
       "\n",
       "   AMT_INCOME_TOTAL  AMT_CREDIT  NAME_TYPE_SUITE  NAME_INCOME_TYPE  \\\n",
       "0          202500.0    406597.5                0                 7   \n",
       "1          270000.0   1293502.5                1                 4   \n",
       "2           67500.0    135000.0                0                 7   \n",
       "3          135000.0    312682.5                0                 7   \n",
       "4          121500.0    513000.0                0                 7   \n",
       "\n",
       "   NAME_EDUCATION_TYPE      ...       ONGOING_CREDIT  TOTAL_CLOSED  \\\n",
       "0                    4      ...                  2.0      383067.0   \n",
       "1                    1      ...                  1.0      207400.5   \n",
       "2                    4      ...                  0.0      189037.8   \n",
       "3                    4      ...                  0.0           0.0   \n",
       "4                    4      ...                  0.0      146250.0   \n",
       "\n",
       "   CLOSED_CREDIT  MONTHS_BALANCE  SK_DPD  NET_PAID  PREV_CREDIT  \\\n",
       "0            6.0             0.0     0.0       0.0    3402045.0   \n",
       "1            3.0             0.0     0.0       0.0   10159641.0   \n",
       "2            2.0             0.0     0.0       0.0      60318.0   \n",
       "3            0.0            -1.0     0.0       0.0    3745395.0   \n",
       "4            1.0             0.0     0.0       0.0    9733149.0   \n",
       "\n",
       "   DAYS_TERMINATION  NET_PAYMENT  PAYMENT_TIME  \n",
       "0             -17.0        0.000        -388.0  \n",
       "1            -527.0        0.000        -179.0  \n",
       "2            -714.0        0.000         -23.0  \n",
       "3               0.0        0.000        -310.0  \n",
       "4               0.0   -29857.365        -240.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical and numerical column\n",
    "\n",
    "# Define the binary categories\n",
    "BINARY_CAT = ['NAME_CONTRACT_TYPE', 'FLAG_OWN_REALTY', 'NAME_TYPE_SUITE', 'REG_REGION_NOT_LIVE_REGION', 'VALID_MOBILE']\n",
    "\n",
    "# Define the non-binary categories\n",
    "NON_BIN_CAT = ['NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE']\n",
    "\n",
    "# Define all the categorical columns\n",
    "CATEGORICAL = BINARY_CAT + NON_BIN_CAT\n",
    "\n",
    "# Define the numerical columns. All the dtype float64s are numerical columns\n",
    "NUMERICAL = [col for col in train_df if train_df[col].dtype == 'float64']\n",
    "\n",
    "# I'll define the additional numerical columns here\n",
    "ADD_NUMERICAL = ['CNT_CHILDREN', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_ID_PUBLISH', 'DOCUMENTS']\n",
    "\n",
    "# Define the complete numerical list\n",
    "NUMERICAL += ADD_NUMERICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to remove that were deemed as poor predictors\n",
    "TO_REMOVE = ['OWN_CAR_AGE', 'ENQUIRIES', 'SK_DPD', 'DAYS_TERMINATION', 'VALID_MOBILE']\n",
    "\n",
    "# Remove the columns from the training data\n",
    "train_df.drop(TO_REMOVE, axis=1, inplace=True)\n",
    "\n",
    "# Remove the columns from the test data\n",
    "test_df.drop(TO_REMOVE, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove poor predictors from CATEGORICAL list\n",
    "CATEGORICAL.remove('VALID_MOBILE')\n",
    "\n",
    "# Remove poor predictors from NUMERICAL list\n",
    "for col in ['OWN_CAR_AGE', 'ENQUIRIES', 'SK_DPD', 'DAYS_TERMINATION']:\n",
    "    NUMERICAL.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove SK_ID_cURR??? since it's supposed to be the index not a training variable\n",
    "\n",
    "# Split the training data\n",
    "\n",
    "# Split the data into X(variables) and y(target)\n",
    "X = train_df.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
    "y = train_df['TARGET']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the training data\n",
    "\n",
    "# # Split the data into X(variables) and y(target)\n",
    "# X = train_df.drop('TARGET', axis=1)\n",
    "# y = train_df['TARGET']\n",
    "\n",
    "# # Split the data into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to match the sample submission format\n",
    "def submission(prediction):\n",
    "    '''Creates the dataframe for the predictions and proper formatting'''\n",
    "    submit = test_df[['SK_ID_CURR']].copy()\n",
    "    submit['TARGET'] = prediction\n",
    "    return submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use FunctionTransformer to retrieve the categorical data and numerical data\n",
    "get_categorical = FunctionTransformer(lambda x: x[CATEGORICAL], validate=False)\n",
    "\n",
    "get_numerical = FunctionTransformer(lambda x: x[NUMERICAL], validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if the function transformers work\n",
    "assert len(CATEGORICAL) == len(get_categorical.fit_transform(train_df).columns)\n",
    "assert len(NUMERICAL) == len(get_numerical.fit_transform(train_df).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FeatureUnion with a nested pipeline\n",
    "process_join_features = FeatureUnion(\n",
    "        transformer_list=[\n",
    "            ('numeric', Pipeline([\n",
    "                ('selector', get_numerical),\n",
    "                ('scaler', MinMaxScaler())\n",
    "            ])),\n",
    "            ('categorical', Pipeline([\n",
    "                ('selector', get_categorical),\n",
    "                ('encoder', OneHotEncoder())\n",
    "            ]))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('numeric', Pipeline(memory=None,\n",
       "     steps=[('selector', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function <lambda> at 0x00000177328EAC80>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y='deprecat...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Pipeline with LogisticRegression\n",
    "lrPipeline = Pipeline([\n",
    "    ('union', process_join_features),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the Pipeline with the training data\n",
    "lrPipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train_values = lrPipeline.predict_proba(X_train)[:, -1]\n",
    "predicted_test_values = lrPipeline.predict_proba(X_test)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6816438927778861\n"
     ]
    }
   ],
   "source": [
    "print (roc_auc_score(y_test, predicted_test_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions from the pipeline\n",
    "lrPredicted = lrPipeline.predict_proba(test_df)[:, -1]\n",
    "\n",
    "# Create the submission dataframe\n",
    "lrPredictions = submission(lrPredicted)\n",
    "\n",
    "# Write the predictions to a csv file\n",
    "lrPredictions.to_csv('./Submissions//lrPredictions.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('numeric', Pipeline(memory=None,\n",
       "     steps=[('selector', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function <lambda> at 0x00000177328EAC80>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y='deprecat...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Pipeline with DecisionTreeClassifier\n",
    "dtPipeline = Pipeline([\n",
    "    ('union', process_join_features),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Fit the Pipeline with the training data\n",
    "dtPipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train_values = dtPipeline.predict_proba(X_train)[:, -1]\n",
    "predicted_test_values = dtPipeline.predict_proba(X_test)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525174506019423\n"
     ]
    }
   ],
   "source": [
    "print (roc_auc_score(y_test, predicted_test_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions from the pipeline\n",
    "dtPredicted = dtPipeline.predict_proba(test_df)[:, -1]\n",
    "\n",
    "# Create the submission dataframe\n",
    "dtPredictions = submission(dtPredicted)\n",
    "\n",
    "# Write the predictions to a csv file\n",
    "dtPredictions.to_csv('./Submissions//dtPredictions.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('numeric', Pipeline(memory=None,\n",
       "     steps=[('selector', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function <lambda> at 0x00000177328EAC80>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y='deprecat...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Pipeline with RandomForestClassifier\n",
    "rfPipeline = Pipeline([\n",
    "    ('union', process_join_features),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit the Pipeline with the training data\n",
    "rfPipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train_values = rfPipeline.predict_proba(X_train)[:, -1]\n",
    "predicted_test_values = rfPipeline.predict_proba(X_test)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6007047529465207\n"
     ]
    }
   ],
   "source": [
    "print (roc_auc_score(y_test, predicted_test_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions from the pipeline\n",
    "rfPredicted = rfPipeline.predict_proba(test_df)[:, -1]\n",
    "\n",
    "# Create the submission dataframe\n",
    "rfPredictions = submission(rfPredicted)\n",
    "\n",
    "# Write the predictions to a csv file\n",
    "rfPredictions.to_csv('./Submissions//rfPredictions.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('numeric', Pipeline(memory=None,\n",
       "     steps=[('selector', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function <lambda> at 0x00000177328EAC80>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y='deprecat...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Pipeline with LinearSVC\n",
    "svcPipeline = Pipeline([\n",
    "    ('union', process_join_features),\n",
    "    ('clf', LinearSVC())\n",
    "])\n",
    "\n",
    "# Fit the Pipeline with the training data\n",
    "svcPipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train_values = svcPipeline.decision_function(X_train)#[:, -1]\n",
    "predicted_test_values = svcPipeline.decision_function(X_test)#[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.80051466, -0.91324142, -0.65885526, ..., -0.80803819,\n",
       "       -0.91029166, -0.82523187])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_train_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6814275258498907\n"
     ]
    }
   ],
   "source": [
    "print (roc_auc_score(y_test, predicted_test_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the predictions from the pipeline\n",
    "svcPredicted = svcPipeline.decision_function(test_df)#[:, -1]\n",
    "\n",
    "# Create the submission dataframe\n",
    "svcPredictions = submission(svcPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the predictions\n",
    "svcPredictions['TARGET'] =(svcPredictions['TARGET']-svcPredictions['TARGET'].\n",
    "                min())/(svcPredictions['TARGET'].max()-svcPredictions['TARGET'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48744.000000</td>\n",
       "      <td>48744.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>277796.676350</td>\n",
       "      <td>0.387691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>103169.547296</td>\n",
       "      <td>0.104054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>188557.750000</td>\n",
       "      <td>0.283527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>277549.000000</td>\n",
       "      <td>0.423152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>367555.500000</td>\n",
       "      <td>0.465282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>456250.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SK_ID_CURR        TARGET\n",
       "count   48744.000000  48744.000000\n",
       "mean   277796.676350      0.387691\n",
       "std    103169.547296      0.104054\n",
       "min    100001.000000      0.000000\n",
       "25%    188557.750000      0.283527\n",
       "50%    277549.000000      0.423152\n",
       "75%    367555.500000      0.465282\n",
       "max    456250.000000      1.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcPredictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the predictions to a csv file\n",
    "svcPredictions.to_csv('./Submissions//svcPredictions.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
